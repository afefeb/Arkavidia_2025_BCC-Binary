{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path ke folder yang berisi file-file DataFrame\n",
    "folder_path = '../comodity-price-prediction-penyisihan-arkavidia-9/Harga Bahan Pangan/train'\n",
    "\n",
    "# Dictionary untuk menyimpan semua DataFrame dengan nama file sebagai key\n",
    "df_dict = {}\n",
    "\n",
    "# Loop melalui semua file dalam folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Pastikan file yang dibaca adalah file yang diinginkan (misalnya, CSV)\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Buat path lengkap ke file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Baca file dan simpan ke dictionary dengan nama file sebagai key\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_dict[file_name] = df  # Gunakan nama file sebagai key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bawang_merah = df_dict['Bawang Merah.csv']\n",
    "df_bawang_putih = df_dict['Bawang Putih Bonggol.csv']\n",
    "df_beras_medium = df_dict['Beras Medium.csv']\n",
    "df_beras_premium = df_dict['Beras Premium.csv']\n",
    "df_cabai_merah_keriting = df_dict['Cabai Merah Keriting.csv']\n",
    "df_cabai_rawit_merah = df_dict['Cabai Rawit Merah.csv']\n",
    "df_daging_ayam = df_dict['Daging Ayam Ras.csv']\n",
    "df_daging_sapi = df_dict['Daging Sapi Murni.csv']\n",
    "df_gula = df_dict['Gula Konsumsi.csv']\n",
    "df_minyak_goreng_curah = df_dict['Minyak Goreng Curah.csv']\n",
    "df_minyak_goreng_kemasan = df_dict['Minyak Goreng Kemasan Sederhana.csv']\n",
    "df_telur_ayam = df_dict['Telur Ayam Ras.csv']\n",
    "df_tepung_terigu = df_dict['Tepung Terigu (Curah).csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List semua dataframe\n",
    "df_list = [\n",
    "    df_bawang_merah, df_bawang_putih, df_beras_medium, df_beras_premium, df_cabai_merah_keriting,\n",
    "    df_cabai_rawit_merah, df_daging_ayam, df_daging_sapi, df_gula, df_minyak_goreng_curah,\n",
    "    df_minyak_goreng_kemasan, df_telur_ayam, df_tepung_terigu\n",
    "]\n",
    "\n",
    "# Loop setiap dataframe dan lakukan interpolasi\n",
    "for i in range(len(df_list)):\n",
    "    df = df_list[i]  # Ambil dataframe\n",
    "\n",
    "    # Pisahkan kolom tanggal (asumsi ada kolom 'date' atau 'tanggal')\n",
    "    date_cols = df.select_dtypes(include=['datetime64', 'object'])  # Deteksi kolom tanggal\n",
    "    num_cols = df.select_dtypes(include=['number'])  # Ambil hanya kolom numerik\n",
    "\n",
    "    # Interpolasi hanya untuk kolom numerik\n",
    "    df_num_imputed = num_cols.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Gabungkan kembali kolom tanggal dengan hasil interpolasi\n",
    "    df_list[i] = pd.concat([date_cols.reset_index(drop=True), df_num_imputed.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'Bawang Merah': df_list[0],\n",
    "    'Bawang Putih Bonggol': df_list[1],\n",
    "    'Beras Medium': df_list[2],\n",
    "    'Beras Premium': df_list[3],\n",
    "    'Cabai Merah Keriting': df_list[4],\n",
    "    'Cabai Rawit Merah': df_list[5],\n",
    "    'Daging Ayam Ras': df_list[6],\n",
    "    'Daging Sapi Murni': df_list[7],\n",
    "    'Gula Konsumsi': df_list[8],\n",
    "    'Minyak Goreng Curah': df_list[9],\n",
    "    'Minyak Goreng Kemasan Sederhana': df_list[10],\n",
    "    'Telur Ayam Ras': df_list[11],\n",
    "    'Tepung Terigu (Curah)': df_list[12]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usd= pd.read_csv('usd_idr_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14301.299805</td>\n",
       "      <td>14207.500000</td>\n",
       "      <td>14246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14301.299805</td>\n",
       "      <td>14207.500000</td>\n",
       "      <td>14246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14215.000000</td>\n",
       "      <td>14301.299805</td>\n",
       "      <td>14207.500000</td>\n",
       "      <td>14246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>14283.599609</td>\n",
       "      <td>14283.599609</td>\n",
       "      <td>14383.299805</td>\n",
       "      <td>14259.000000</td>\n",
       "      <td>14303.700195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>14385.500000</td>\n",
       "      <td>14385.500000</td>\n",
       "      <td>14398.500000</td>\n",
       "      <td>14336.700195</td>\n",
       "      <td>14346.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>15201.500000</td>\n",
       "      <td>15201.500000</td>\n",
       "      <td>15204.000000</td>\n",
       "      <td>14975.700195</td>\n",
       "      <td>15201.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>15070.000000</td>\n",
       "      <td>15070.000000</td>\n",
       "      <td>15161.700195</td>\n",
       "      <td>15019.299805</td>\n",
       "      <td>15070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>15086.000000</td>\n",
       "      <td>15086.000000</td>\n",
       "      <td>15173.566732</td>\n",
       "      <td>14991.500000</td>\n",
       "      <td>15086.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>15102.000000</td>\n",
       "      <td>15102.000000</td>\n",
       "      <td>15185.433268</td>\n",
       "      <td>14963.700195</td>\n",
       "      <td>15102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>15118.000000</td>\n",
       "      <td>15118.000000</td>\n",
       "      <td>15197.299805</td>\n",
       "      <td>14935.900391</td>\n",
       "      <td>15118.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Adj Close         Close          High           Low  \\\n",
       "0     2022-01-01  14215.000000  14215.000000  14301.299805  14207.500000   \n",
       "1     2022-01-02  14215.000000  14215.000000  14301.299805  14207.500000   \n",
       "2     2022-01-03  14215.000000  14215.000000  14301.299805  14207.500000   \n",
       "3     2022-01-04  14283.599609  14283.599609  14383.299805  14259.000000   \n",
       "4     2022-01-05  14385.500000  14385.500000  14398.500000  14336.700195   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "999   2024-09-26  15201.500000  15201.500000  15204.000000  14975.700195   \n",
       "1000  2024-09-27  15070.000000  15070.000000  15161.700195  15019.299805   \n",
       "1001  2024-09-28  15086.000000  15086.000000  15173.566732  14991.500000   \n",
       "1002  2024-09-29  15102.000000  15102.000000  15185.433268  14963.700195   \n",
       "1003  2024-09-30  15118.000000  15118.000000  15197.299805  14935.900391   \n",
       "\n",
       "              Open  \n",
       "0     14246.000000  \n",
       "1     14246.000000  \n",
       "2     14246.000000  \n",
       "3     14303.700195  \n",
       "4     14346.400391  \n",
       "...            ...  \n",
       "999   15201.500000  \n",
       "1000  15070.000000  \n",
       "1001  15086.000000  \n",
       "1002  15102.000000  \n",
       "1003  15118.000000  \n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usd = df_usd.drop(columns='Volume')\n",
    "\n",
    "df_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Parameter\n",
    "seq_length = 30  # Panjang sequence\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "# Rentang waktu prediksi\n",
    "predict_start = '2024-10-01'\n",
    "predict_end = '2024-12-31'\n",
    "predict_periods = (pd.to_datetime(predict_end) - pd.to_datetime(predict_start)).days + 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultivariateLSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=64, num_layers=3, output_size=1):\n",
    "        super(MultivariateLSTM, self).__init__()\n",
    "\n",
    "        # LSTM dengan bidirectional=True agar melihat pola dua arah\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=0.3, bidirectional=True)\n",
    "\n",
    "        # Batch Normalization agar training lebih stabil\n",
    "        self.batch_norm = nn.BatchNorm1d(2 * hidden_size)  # Karena bidirectional, hidden_size jadi 2x\n",
    "\n",
    "        # Fully Connected Layer dengan Activation Function\n",
    "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()  # Activation agar output lebih fleksibel\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Ambil output terakhir\n",
    "        lstm_out = self.batch_norm(lstm_out)  # Normalisasi\n",
    "        return self.fc(self.relu(lstm_out))  # Lewat activation dulu sebelum FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direktori penyimpanan model terbaik\n",
    "if not os.path.exists(\"best_models\"): os.makedirs(\"best_models\")\n",
    "\n",
    "# Menyimpan hasil prediksi dan MAPE terbaik\n",
    "all_predictions = []\n",
    "mape_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Memproses Bawang Merah ===\n",
      "  â†’ Prediksi untuk Aceh...\n",
      "Epoch 10/100, Training Loss: 0.089073, Validation Loss: 0.282108, MAPE: 0.362123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Training Loss: 0.050904, Validation Loss: 0.257361, MAPE: 0.327371\n",
      "Epoch 30/100, Training Loss: 0.041189, Validation Loss: 0.268156, MAPE: 0.339613\n",
      "Epoch 40/100, Training Loss: 0.031543, Validation Loss: 0.259875, MAPE: 0.334414\n",
      "Epoch 50/100, Training Loss: 0.030242, Validation Loss: 0.212859, MAPE: 0.283956\n",
      "Epoch 60/100, Training Loss: 0.028335, Validation Loss: 0.172638, MAPE: 0.253355\n",
      "Epoch 70/100, Training Loss: 0.027036, Validation Loss: 0.144185, MAPE: 0.238012\n",
      "Epoch 80/100, Training Loss: 0.025429, Validation Loss: 0.140595, MAPE: 0.236615\n",
      "Epoch 90/100, Training Loss: 0.026529, Validation Loss: 0.155990, MAPE: 0.245205\n",
      "Epoch 100/100, Training Loss: 0.025776, Validation Loss: 0.186683, MAPE: 0.261632\n",
      "  â†’ Prediksi untuk Bali...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.054081, Validation Loss: 0.163400, MAPE: 0.379858\n",
      "Epoch 20/100, Training Loss: 0.040850, Validation Loss: 0.170214, MAPE: 0.391931\n",
      "Epoch 30/100, Training Loss: 0.035100, Validation Loss: 0.175937, MAPE: 0.402527\n",
      "Epoch 40/100, Training Loss: 0.030314, Validation Loss: 0.176030, MAPE: 0.401191\n",
      "Epoch 50/100, Training Loss: 0.029267, Validation Loss: 0.204515, MAPE: 0.446560\n",
      "Epoch 60/100, Training Loss: 0.028078, Validation Loss: 0.206636, MAPE: 0.446010\n",
      "Epoch 70/100, Training Loss: 0.026893, Validation Loss: 0.229577, MAPE: 0.476023\n",
      "Epoch 80/100, Training Loss: 0.026891, Validation Loss: 0.256240, MAPE: 0.514331\n",
      "Epoch 90/100, Training Loss: 0.025592, Validation Loss: 0.239409, MAPE: 0.489346\n",
      "Epoch 100/100, Training Loss: 0.026378, Validation Loss: 0.238948, MAPE: 0.487099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Banten...\n",
      "Epoch 10/100, Training Loss: 0.059085, Validation Loss: 0.125280, MAPE: 0.272647\n",
      "Epoch 20/100, Training Loss: 0.048316, Validation Loss: 0.139132, MAPE: 0.304493\n",
      "Epoch 30/100, Training Loss: 0.039633, Validation Loss: 0.147682, MAPE: 0.324595\n",
      "Epoch 40/100, Training Loss: 0.031084, Validation Loss: 0.143734, MAPE: 0.313803\n",
      "Epoch 50/100, Training Loss: 0.029969, Validation Loss: 0.165968, MAPE: 0.353938\n",
      "Epoch 60/100, Training Loss: 0.025710, Validation Loss: 0.182274, MAPE: 0.386269\n",
      "Epoch 70/100, Training Loss: 0.024635, Validation Loss: 0.229435, MAPE: 0.468446\n",
      "Epoch 80/100, Training Loss: 0.022341, Validation Loss: 0.209814, MAPE: 0.433669\n",
      "Epoch 90/100, Training Loss: 0.021263, Validation Loss: 0.176968, MAPE: 0.373598\n",
      "Epoch 100/100, Training Loss: 0.020877, Validation Loss: 0.189785, MAPE: 0.394103\n",
      "  â†’ Prediksi untuk Bengkulu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.062987, Validation Loss: 0.301194, MAPE: 0.463026\n",
      "Epoch 20/100, Training Loss: 0.047792, Validation Loss: 0.297486, MAPE: 0.458906\n",
      "Epoch 30/100, Training Loss: 0.038011, Validation Loss: 0.311398, MAPE: 0.472909\n",
      "Epoch 40/100, Training Loss: 0.034140, Validation Loss: 0.302772, MAPE: 0.460465\n",
      "Epoch 50/100, Training Loss: 0.031634, Validation Loss: 0.332698, MAPE: 0.490066\n",
      "Epoch 60/100, Training Loss: 0.027894, Validation Loss: 0.329817, MAPE: 0.482893\n",
      "Epoch 70/100, Training Loss: 0.025770, Validation Loss: 0.376323, MAPE: 0.524161\n",
      "Epoch 80/100, Training Loss: 0.025956, Validation Loss: 0.508332, MAPE: 0.651477\n",
      "Epoch 90/100, Training Loss: 0.025630, Validation Loss: 0.500952, MAPE: 0.641581\n",
      "Epoch 100/100, Training Loss: 0.024977, Validation Loss: 0.491910, MAPE: 0.625367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk DI Yogyakarta...\n",
      "Epoch 10/100, Training Loss: 0.061412, Validation Loss: 0.173238, MAPE: 0.365453\n",
      "Epoch 20/100, Training Loss: 0.043329, Validation Loss: 0.196505, MAPE: 0.414681\n",
      "Epoch 30/100, Training Loss: 0.041187, Validation Loss: 0.204642, MAPE: 0.429451\n",
      "Epoch 40/100, Training Loss: 0.034709, Validation Loss: 0.234346, MAPE: 0.477918\n",
      "Epoch 50/100, Training Loss: 0.029221, Validation Loss: 0.276493, MAPE: 0.543169\n",
      "Epoch 60/100, Training Loss: 0.028602, Validation Loss: 0.322135, MAPE: 0.601665\n",
      "Epoch 70/100, Training Loss: 0.027819, Validation Loss: 0.410986, MAPE: 0.705590\n",
      "Epoch 80/100, Training Loss: 0.027051, Validation Loss: 0.460566, MAPE: 0.763947\n",
      "Epoch 90/100, Training Loss: 0.026549, Validation Loss: 0.487759, MAPE: 0.794604\n",
      "Epoch 100/100, Training Loss: 0.026960, Validation Loss: 0.503139, MAPE: 0.812837\n",
      "  â†’ Prediksi untuk DKI Jakarta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.056009, Validation Loss: 0.216061, MAPE: 0.343082\n",
      "Epoch 20/100, Training Loss: 0.038473, Validation Loss: 0.235558, MAPE: 0.369102\n",
      "Epoch 30/100, Training Loss: 0.033105, Validation Loss: 0.248184, MAPE: 0.386521\n",
      "Epoch 40/100, Training Loss: 0.027046, Validation Loss: 0.269851, MAPE: 0.410720\n",
      "Epoch 50/100, Training Loss: 0.023735, Validation Loss: 0.288827, MAPE: 0.429709\n",
      "Epoch 60/100, Training Loss: 0.022178, Validation Loss: 0.291247, MAPE: 0.431113\n",
      "Epoch 70/100, Training Loss: 0.021402, Validation Loss: 0.326911, MAPE: 0.465522\n",
      "Epoch 80/100, Training Loss: 0.020670, Validation Loss: 0.391916, MAPE: 0.530178\n",
      "Epoch 90/100, Training Loss: 0.019896, Validation Loss: 0.405928, MAPE: 0.546921\n",
      "Epoch 100/100, Training Loss: 0.018393, Validation Loss: 0.408027, MAPE: 0.554914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Gorontalo...\n",
      "Epoch 10/100, Training Loss: 0.059609, Validation Loss: 0.088132, MAPE: 0.305532\n",
      "Epoch 20/100, Training Loss: 0.052174, Validation Loss: 0.092486, MAPE: 0.316524\n",
      "Epoch 30/100, Training Loss: 0.044075, Validation Loss: 0.098885, MAPE: 0.334159\n",
      "Epoch 40/100, Training Loss: 0.034768, Validation Loss: 0.093613, MAPE: 0.319531\n",
      "Epoch 50/100, Training Loss: 0.032029, Validation Loss: 0.104674, MAPE: 0.344141\n",
      "Epoch 60/100, Training Loss: 0.030263, Validation Loss: 0.099596, MAPE: 0.330797\n",
      "Epoch 70/100, Training Loss: 0.029194, Validation Loss: 0.111910, MAPE: 0.358848\n",
      "Epoch 80/100, Training Loss: 0.029124, Validation Loss: 0.127179, MAPE: 0.393856\n",
      "Epoch 90/100, Training Loss: 0.027936, Validation Loss: 0.107369, MAPE: 0.353421\n",
      "Epoch 100/100, Training Loss: 0.027212, Validation Loss: 0.112308, MAPE: 0.371869\n",
      "  â†’ Prediksi untuk Jambi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.067813, Validation Loss: 0.231279, MAPE: 0.321319\n",
      "Epoch 20/100, Training Loss: 0.053344, Validation Loss: 0.244554, MAPE: 0.337614\n",
      "Epoch 30/100, Training Loss: 0.043106, Validation Loss: 0.240737, MAPE: 0.332385\n",
      "Epoch 40/100, Training Loss: 0.038708, Validation Loss: 0.249968, MAPE: 0.341631\n",
      "Epoch 50/100, Training Loss: 0.036971, Validation Loss: 0.261487, MAPE: 0.352074\n",
      "Epoch 60/100, Training Loss: 0.034267, Validation Loss: 0.282605, MAPE: 0.370348\n",
      "Epoch 70/100, Training Loss: 0.033057, Validation Loss: 0.328399, MAPE: 0.412653\n",
      "Epoch 80/100, Training Loss: 0.033482, Validation Loss: 0.393593, MAPE: 0.471732\n",
      "Epoch 90/100, Training Loss: 0.033015, Validation Loss: 0.382360, MAPE: 0.457400\n",
      "Epoch 100/100, Training Loss: 0.031644, Validation Loss: 0.416053, MAPE: 0.485627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Jawa Barat...\n",
      "Epoch 10/100, Training Loss: 0.054094, Validation Loss: 0.156927, MAPE: 0.331487\n",
      "Epoch 20/100, Training Loss: 0.040408, Validation Loss: 0.170060, MAPE: 0.353834\n",
      "Epoch 30/100, Training Loss: 0.034066, Validation Loss: 0.176365, MAPE: 0.365766\n",
      "Epoch 40/100, Training Loss: 0.031219, Validation Loss: 0.184720, MAPE: 0.377704\n",
      "Epoch 50/100, Training Loss: 0.027858, Validation Loss: 0.209584, MAPE: 0.415492\n",
      "Epoch 60/100, Training Loss: 0.025489, Validation Loss: 0.238795, MAPE: 0.455834\n",
      "Epoch 70/100, Training Loss: 0.023309, Validation Loss: 0.327283, MAPE: 0.568383\n",
      "Epoch 80/100, Training Loss: 0.022521, Validation Loss: 0.397910, MAPE: 0.643517\n",
      "Epoch 90/100, Training Loss: 0.021784, Validation Loss: 0.399655, MAPE: 0.646478\n",
      "Epoch 100/100, Training Loss: 0.021484, Validation Loss: 0.377104, MAPE: 0.617838\n",
      "  â†’ Prediksi untuk Jawa Tengah...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.082023, Validation Loss: 0.158600, MAPE: 0.354749\n",
      "Epoch 20/100, Training Loss: 0.052706, Validation Loss: 0.181780, MAPE: 0.402229\n",
      "Epoch 30/100, Training Loss: 0.039414, Validation Loss: 0.185631, MAPE: 0.407102\n",
      "Epoch 40/100, Training Loss: 0.037510, Validation Loss: 0.198069, MAPE: 0.426444\n",
      "Epoch 50/100, Training Loss: 0.033824, Validation Loss: 0.216727, MAPE: 0.454025\n",
      "Epoch 60/100, Training Loss: 0.033522, Validation Loss: 0.263774, MAPE: 0.521299\n",
      "Epoch 70/100, Training Loss: 0.028752, Validation Loss: 0.367377, MAPE: 0.660999\n",
      "Epoch 80/100, Training Loss: 0.027204, Validation Loss: 0.405211, MAPE: 0.698445\n",
      "Epoch 90/100, Training Loss: 0.027390, Validation Loss: 0.470143, MAPE: 0.763323\n",
      "Epoch 100/100, Training Loss: 0.026272, Validation Loss: 0.456506, MAPE: 0.740615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Jawa Timur...\n",
      "Epoch 10/100, Training Loss: 0.047701, Validation Loss: 0.114793, MAPE: 0.292816\n",
      "Epoch 20/100, Training Loss: 0.036814, Validation Loss: 0.115570, MAPE: 0.293610\n",
      "Epoch 30/100, Training Loss: 0.032701, Validation Loss: 0.116589, MAPE: 0.295149\n",
      "Epoch 40/100, Training Loss: 0.030371, Validation Loss: 0.125355, MAPE: 0.312329\n",
      "Epoch 50/100, Training Loss: 0.027977, Validation Loss: 0.150060, MAPE: 0.363420\n",
      "Epoch 60/100, Training Loss: 0.027193, Validation Loss: 0.163493, MAPE: 0.387612\n",
      "Epoch 70/100, Training Loss: 0.025994, Validation Loss: 0.219916, MAPE: 0.493001\n",
      "Epoch 80/100, Training Loss: 0.026515, Validation Loss: 0.272594, MAPE: 0.579742\n",
      "Epoch 90/100, Training Loss: 0.025475, Validation Loss: 0.283606, MAPE: 0.594481\n",
      "Epoch 100/100, Training Loss: 0.024343, Validation Loss: 0.327404, MAPE: 0.667821\n",
      "  â†’ Prediksi untuk Kalimantan Barat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.066260, Validation Loss: 0.060619, MAPE: 0.210834\n",
      "Epoch 20/100, Training Loss: 0.049792, Validation Loss: 0.075092, MAPE: 0.245820\n",
      "Epoch 30/100, Training Loss: 0.041987, Validation Loss: 0.078218, MAPE: 0.251154\n",
      "Epoch 40/100, Training Loss: 0.036727, Validation Loss: 0.099008, MAPE: 0.291058\n",
      "Epoch 50/100, Training Loss: 0.034832, Validation Loss: 0.127895, MAPE: 0.338442\n",
      "Epoch 60/100, Training Loss: 0.031234, Validation Loss: 0.152855, MAPE: 0.375583\n",
      "Epoch 70/100, Training Loss: 0.030431, Validation Loss: 0.200926, MAPE: 0.442955\n",
      "Epoch 80/100, Training Loss: 0.030044, Validation Loss: 0.218505, MAPE: 0.468322\n",
      "Epoch 90/100, Training Loss: 0.027756, Validation Loss: 0.230520, MAPE: 0.487063\n",
      "Epoch 100/100, Training Loss: 0.027909, Validation Loss: 0.166786, MAPE: 0.406751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Kalimantan Selatan...\n",
      "Epoch 10/100, Training Loss: 0.042502, Validation Loss: 0.079699, MAPE: 0.306225\n",
      "Epoch 20/100, Training Loss: 0.033993, Validation Loss: 0.079072, MAPE: 0.302592\n",
      "Epoch 30/100, Training Loss: 0.029227, Validation Loss: 0.083523, MAPE: 0.316337\n",
      "Epoch 40/100, Training Loss: 0.023669, Validation Loss: 0.096954, MAPE: 0.355344\n",
      "Epoch 50/100, Training Loss: 0.022309, Validation Loss: 0.115730, MAPE: 0.404942\n",
      "Epoch 60/100, Training Loss: 0.021983, Validation Loss: 0.142360, MAPE: 0.465972\n",
      "Epoch 70/100, Training Loss: 0.021340, Validation Loss: 0.224199, MAPE: 0.637365\n",
      "Epoch 80/100, Training Loss: 0.020577, Validation Loss: 0.143968, MAPE: 0.472871\n",
      "Epoch 90/100, Training Loss: 0.019744, Validation Loss: 0.131137, MAPE: 0.442416\n",
      "Epoch 100/100, Training Loss: 0.019018, Validation Loss: 0.094227, MAPE: 0.344279\n",
      "  â†’ Prediksi untuk Kalimantan Tengah...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.072774, Validation Loss: 0.096771, MAPE: 0.294505\n",
      "Epoch 20/100, Training Loss: 0.053266, Validation Loss: 0.105921, MAPE: 0.314242\n",
      "Epoch 30/100, Training Loss: 0.043952, Validation Loss: 0.121125, MAPE: 0.345316\n",
      "Epoch 40/100, Training Loss: 0.035765, Validation Loss: 0.123949, MAPE: 0.347220\n",
      "Epoch 50/100, Training Loss: 0.032295, Validation Loss: 0.154368, MAPE: 0.399780\n",
      "Epoch 60/100, Training Loss: 0.030209, Validation Loss: 0.186623, MAPE: 0.446507\n",
      "Epoch 70/100, Training Loss: 0.028038, Validation Loss: 0.204593, MAPE: 0.466716\n",
      "Epoch 80/100, Training Loss: 0.029174, Validation Loss: 0.262234, MAPE: 0.546704\n",
      "Epoch 90/100, Training Loss: 0.028348, Validation Loss: 0.323208, MAPE: 0.623194\n",
      "Epoch 100/100, Training Loss: 0.027968, Validation Loss: 0.361446, MAPE: 0.669088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Kalimantan Timur...\n",
      "Epoch 10/100, Training Loss: 0.054676, Validation Loss: 0.106623, MAPE: 0.393217\n",
      "Epoch 20/100, Training Loss: 0.043915, Validation Loss: 0.113066, MAPE: 0.404834\n",
      "Epoch 30/100, Training Loss: 0.033609, Validation Loss: 0.105216, MAPE: 0.387869\n",
      "Epoch 40/100, Training Loss: 0.026414, Validation Loss: 0.099111, MAPE: 0.374324\n",
      "Epoch 50/100, Training Loss: 0.024494, Validation Loss: 0.092690, MAPE: 0.360981\n",
      "Epoch 60/100, Training Loss: 0.023108, Validation Loss: 0.064041, MAPE: 0.286301\n",
      "Epoch 70/100, Training Loss: 0.020304, Validation Loss: 0.038930, MAPE: 0.212268\n",
      "Epoch 80/100, Training Loss: 0.020348, Validation Loss: 0.026161, MAPE: 0.168611\n",
      "Epoch 90/100, Training Loss: 0.019155, Validation Loss: 0.024317, MAPE: 0.158107\n",
      "Epoch 100/100, Training Loss: 0.018895, Validation Loss: 0.028071, MAPE: 0.168500\n",
      "  â†’ Prediksi untuk Kalimantan Utara...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.069221, Validation Loss: 0.073494, MAPE: 0.200083\n",
      "Epoch 20/100, Training Loss: 0.048420, Validation Loss: 0.084491, MAPE: 0.219958\n",
      "Epoch 30/100, Training Loss: 0.035107, Validation Loss: 0.086124, MAPE: 0.222131\n",
      "Epoch 40/100, Training Loss: 0.033307, Validation Loss: 0.100802, MAPE: 0.247357\n",
      "Epoch 50/100, Training Loss: 0.030427, Validation Loss: 0.105256, MAPE: 0.255936\n",
      "Epoch 60/100, Training Loss: 0.027802, Validation Loss: 0.129259, MAPE: 0.291076\n",
      "Epoch 70/100, Training Loss: 0.026082, Validation Loss: 0.147343, MAPE: 0.321059\n",
      "Epoch 80/100, Training Loss: 0.025539, Validation Loss: 0.123631, MAPE: 0.292795\n",
      "Epoch 90/100, Training Loss: 0.024668, Validation Loss: 0.081391, MAPE: 0.223841\n",
      "Epoch 100/100, Training Loss: 0.023020, Validation Loss: 0.056833, MAPE: 0.175722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Kepulauan Bangka Belitung...\n",
      "Epoch 10/100, Training Loss: 0.072800, Validation Loss: 0.187502, MAPE: 0.334530\n",
      "Epoch 20/100, Training Loss: 0.060603, Validation Loss: 0.174058, MAPE: 0.306335\n",
      "Epoch 30/100, Training Loss: 0.038499, Validation Loss: 0.180500, MAPE: 0.315739\n",
      "Epoch 40/100, Training Loss: 0.033803, Validation Loss: 0.176688, MAPE: 0.311748\n",
      "Epoch 50/100, Training Loss: 0.031687, Validation Loss: 0.180305, MAPE: 0.315290\n",
      "Epoch 60/100, Training Loss: 0.029745, Validation Loss: 0.197318, MAPE: 0.339651\n",
      "Epoch 70/100, Training Loss: 0.027028, Validation Loss: 0.213205, MAPE: 0.362448\n",
      "Epoch 80/100, Training Loss: 0.026046, Validation Loss: 0.220122, MAPE: 0.369783\n",
      "Epoch 90/100, Training Loss: 0.024467, Validation Loss: 0.243177, MAPE: 0.395945\n",
      "Epoch 100/100, Training Loss: 0.024862, Validation Loss: 0.311013, MAPE: 0.476178\n",
      "  â†’ Prediksi untuk Kepulauan Riau...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.145055, Validation Loss: 0.278099, MAPE: 0.205904\n",
      "Epoch 20/100, Training Loss: 0.064001, Validation Loss: 0.239806, MAPE: 0.189348\n",
      "Epoch 30/100, Training Loss: 0.061909, Validation Loss: 0.252762, MAPE: 0.194939\n",
      "Epoch 40/100, Training Loss: 0.039606, Validation Loss: 0.272679, MAPE: 0.203243\n",
      "Epoch 50/100, Training Loss: 0.039236, Validation Loss: 0.257612, MAPE: 0.197631\n",
      "Epoch 60/100, Training Loss: 0.035126, Validation Loss: 0.252225, MAPE: 0.194170\n",
      "Epoch 70/100, Training Loss: 0.034030, Validation Loss: 0.204004, MAPE: 0.171800\n",
      "Epoch 80/100, Training Loss: 0.033040, Validation Loss: 0.186095, MAPE: 0.163867\n",
      "Epoch 90/100, Training Loss: 0.033798, Validation Loss: 0.177172, MAPE: 0.158291\n",
      "Epoch 100/100, Training Loss: 0.030189, Validation Loss: 0.168234, MAPE: 0.152984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Lampung...\n",
      "Epoch 10/100, Training Loss: 0.051091, Validation Loss: 0.177293, MAPE: 0.311116\n",
      "Epoch 20/100, Training Loss: 0.037745, Validation Loss: 0.181989, MAPE: 0.317574\n",
      "Epoch 30/100, Training Loss: 0.032823, Validation Loss: 0.194500, MAPE: 0.335526\n",
      "Epoch 40/100, Training Loss: 0.029068, Validation Loss: 0.211196, MAPE: 0.361200\n",
      "Epoch 50/100, Training Loss: 0.027751, Validation Loss: 0.248846, MAPE: 0.421854\n",
      "Epoch 60/100, Training Loss: 0.025573, Validation Loss: 0.261406, MAPE: 0.449792\n",
      "Epoch 70/100, Training Loss: 0.023323, Validation Loss: 0.250316, MAPE: 0.437523\n",
      "Epoch 80/100, Training Loss: 0.022331, Validation Loss: 0.227242, MAPE: 0.394120\n",
      "Epoch 90/100, Training Loss: 0.022034, Validation Loss: 0.211003, MAPE: 0.362145\n",
      "Epoch 100/100, Training Loss: 0.022225, Validation Loss: 0.192325, MAPE: 0.329912\n",
      "  â†’ Prediksi untuk Maluku Utara...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.051419, Validation Loss: 0.106145, MAPE: 0.241164\n",
      "Epoch 20/100, Training Loss: 0.044373, Validation Loss: 0.115443, MAPE: 0.252823\n",
      "Epoch 30/100, Training Loss: 0.033905, Validation Loss: 0.122771, MAPE: 0.262211\n",
      "Epoch 40/100, Training Loss: 0.029426, Validation Loss: 0.136807, MAPE: 0.279159\n",
      "Epoch 50/100, Training Loss: 0.026638, Validation Loss: 0.160273, MAPE: 0.305537\n",
      "Epoch 60/100, Training Loss: 0.023573, Validation Loss: 0.190128, MAPE: 0.337591\n",
      "Epoch 70/100, Training Loss: 0.021698, Validation Loss: 0.132411, MAPE: 0.276970\n",
      "Epoch 80/100, Training Loss: 0.022061, Validation Loss: 0.114032, MAPE: 0.258399\n",
      "Epoch 90/100, Training Loss: 0.021036, Validation Loss: 0.095466, MAPE: 0.233696\n",
      "Epoch 100/100, Training Loss: 0.021265, Validation Loss: 0.098486, MAPE: 0.235672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Maluku...\n",
      "Epoch 10/100, Training Loss: 0.071216, Validation Loss: 0.152007, MAPE: 0.268823\n",
      "Epoch 20/100, Training Loss: 0.064026, Validation Loss: 0.149171, MAPE: 0.262157\n",
      "Epoch 30/100, Training Loss: 0.045171, Validation Loss: 0.175906, MAPE: 0.293584\n",
      "Epoch 40/100, Training Loss: 0.038914, Validation Loss: 0.185044, MAPE: 0.305019\n",
      "Epoch 50/100, Training Loss: 0.031159, Validation Loss: 0.172132, MAPE: 0.290535\n",
      "Epoch 60/100, Training Loss: 0.028617, Validation Loss: 0.162527, MAPE: 0.284026\n",
      "Epoch 70/100, Training Loss: 0.026729, Validation Loss: 0.092546, MAPE: 0.206343\n",
      "Epoch 80/100, Training Loss: 0.025085, Validation Loss: 0.035806, MAPE: 0.118238\n",
      "Epoch 90/100, Training Loss: 0.023802, Validation Loss: 0.038655, MAPE: 0.125084\n",
      "Epoch 100/100, Training Loss: 0.021456, Validation Loss: 0.079198, MAPE: 0.182814\n",
      "  â†’ Prediksi untuk Nusa Tenggara Barat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.079223, Validation Loss: 0.154048, MAPE: 0.349478\n",
      "Epoch 20/100, Training Loss: 0.068558, Validation Loss: 0.156271, MAPE: 0.351488\n",
      "Epoch 30/100, Training Loss: 0.046194, Validation Loss: 0.159948, MAPE: 0.360414\n",
      "Epoch 40/100, Training Loss: 0.049124, Validation Loss: 0.158236, MAPE: 0.356559\n",
      "Epoch 50/100, Training Loss: 0.040346, Validation Loss: 0.156052, MAPE: 0.346939\n",
      "Epoch 60/100, Training Loss: 0.040312, Validation Loss: 0.166656, MAPE: 0.367127\n",
      "Epoch 70/100, Training Loss: 0.035791, Validation Loss: 0.137285, MAPE: 0.314320\n",
      "Epoch 80/100, Training Loss: 0.034438, Validation Loss: 0.157017, MAPE: 0.346861\n",
      "Epoch 90/100, Training Loss: 0.032737, Validation Loss: 0.192161, MAPE: 0.415952\n",
      "Epoch 100/100, Training Loss: 0.032201, Validation Loss: 0.114162, MAPE: 0.296041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Nusa Tenggara Timur...\n",
      "Epoch 10/100, Training Loss: 0.098093, Validation Loss: 0.246950, MAPE: 0.294124\n",
      "Epoch 20/100, Training Loss: 0.086782, Validation Loss: 0.240793, MAPE: 0.296385\n",
      "Epoch 30/100, Training Loss: 0.059836, Validation Loss: 0.264176, MAPE: 0.305016\n",
      "Epoch 40/100, Training Loss: 0.058698, Validation Loss: 0.250216, MAPE: 0.300484\n",
      "Epoch 50/100, Training Loss: 0.052041, Validation Loss: 0.247478, MAPE: 0.294551\n",
      "Epoch 60/100, Training Loss: 0.048061, Validation Loss: 0.184264, MAPE: 0.264554\n",
      "Epoch 70/100, Training Loss: 0.045026, Validation Loss: 0.100694, MAPE: 0.238995\n",
      "Epoch 80/100, Training Loss: 0.043563, Validation Loss: 0.104793, MAPE: 0.257333\n",
      "Epoch 90/100, Training Loss: 0.042139, Validation Loss: 0.111430, MAPE: 0.285087\n",
      "Epoch 100/100, Training Loss: 0.040859, Validation Loss: 0.145569, MAPE: 0.309265\n",
      "  â†’ Prediksi untuk Papua Barat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.071012, Validation Loss: 0.229947, MAPE: 0.435313\n",
      "Epoch 20/100, Training Loss: 0.061960, Validation Loss: 0.218829, MAPE: 0.423469\n",
      "Epoch 30/100, Training Loss: 0.035682, Validation Loss: 0.230131, MAPE: 0.434167\n",
      "Epoch 40/100, Training Loss: 0.035252, Validation Loss: 0.235688, MAPE: 0.438723\n",
      "Epoch 50/100, Training Loss: 0.027205, Validation Loss: 0.237896, MAPE: 0.439978\n",
      "Epoch 60/100, Training Loss: 0.025692, Validation Loss: 0.272280, MAPE: 0.468292\n",
      "Epoch 70/100, Training Loss: 0.024082, Validation Loss: 0.298480, MAPE: 0.487327\n",
      "Epoch 80/100, Training Loss: 0.022781, Validation Loss: 0.334255, MAPE: 0.513084\n",
      "Epoch 90/100, Training Loss: 0.020759, Validation Loss: 0.406473, MAPE: 0.566877\n",
      "Epoch 100/100, Training Loss: 0.021144, Validation Loss: 0.496510, MAPE: 0.625209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Prediksi untuk Papua...\n",
      "Epoch 10/100, Training Loss: 0.063853, Validation Loss: 0.105235, MAPE: 0.151348\n",
      "Epoch 20/100, Training Loss: 0.044089, Validation Loss: 0.129005, MAPE: 0.174092\n",
      "Epoch 30/100, Training Loss: 0.039516, Validation Loss: 0.146843, MAPE: 0.189528\n",
      "Epoch 40/100, Training Loss: 0.035432, Validation Loss: 0.183400, MAPE: 0.219431\n",
      "Epoch 50/100, Training Loss: 0.026197, Validation Loss: 0.198976, MAPE: 0.233031\n",
      "Epoch 60/100, Training Loss: 0.024325, Validation Loss: 0.159893, MAPE: 0.208473\n",
      "Epoch 70/100, Training Loss: 0.021791, Validation Loss: 0.159545, MAPE: 0.205458\n",
      "Epoch 80/100, Training Loss: 0.021530, Validation Loss: 0.184339, MAPE: 0.222856\n",
      "Epoch 90/100, Training Loss: 0.020521, Validation Loss: 0.165378, MAPE: 0.205548\n",
      "Epoch 100/100, Training Loss: 0.020647, Validation Loss: 0.148897, MAPE: 0.189324\n",
      "  â†’ Prediksi untuk Riau...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66693/3786150980.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_model_path))\n",
      "/home/sirius/Documents/DS/myenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Training Loss: 0.066384, Validation Loss: 0.290662, MAPE: 0.294750\n",
      "Epoch 20/100, Training Loss: 0.051874, Validation Loss: 0.298100, MAPE: 0.300225\n",
      "Epoch 30/100, Training Loss: 0.044328, Validation Loss: 0.300700, MAPE: 0.301274\n",
      "Epoch 40/100, Training Loss: 0.042317, Validation Loss: 0.304540, MAPE: 0.303003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[1;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y_train)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/DS/myenv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DS/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:340\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    331\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    332\u001b[0m     (inputs,)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    339\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 340\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/Documents/DS/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:220\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m    219\u001b[0m         new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 220\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for komoditas, df_komoditas in df_dict.items():\n",
    "    print(f\"\\n=== Memproses {komoditas} ===\")\n",
    "\n",
    "    df_komoditas['Date'] = pd.to_datetime(df_komoditas['Date'])\n",
    "    df_usd['Date'] = pd.to_datetime(df_usd['Date'])  # Data USD/IDR\n",
    "\n",
    "    # Gabungkan dengan data USD/IDR berdasarkan tanggal\n",
    "    df_merged = df_komoditas.merge(df_usd, on='Date', how='left')\n",
    "    \n",
    "    for provinsi in df_komoditas.columns[1:]:\n",
    "        print(f\"  â†’ Prediksi untuk {provinsi}...\")\n",
    "\n",
    "        df_prov = df_merged[['Date', provinsi, 'Adj Close', 'Close', 'High', 'Low', 'Open']].rename(\n",
    "            columns={'Date': 'ds', provinsi: 'y'}\n",
    "        )\n",
    "        \n",
    "        # Normalisasi data\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled = scaler.fit_transform(df_prov[['y', 'Adj Close', 'Close', 'High', 'Low', 'Open']])\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(len(df_scaled) - seq_length):\n",
    "            X.append(df_scaled[i:i+seq_length, 1:])  # Semua fitur kecuali target\n",
    "            y.append(df_scaled[i+seq_length, 0])  # Target harga komoditas\n",
    "        \n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1).to(device)\n",
    "        \n",
    "        # Pisahkan training & testing\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        # Bangun model LSTM\n",
    "        model = MultivariateLSTM(input_size=5).to(device)  # 5 fitur dari USD/IDR\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
    "        \n",
    "        # Menyimpan model terbaik berdasarkan validation loss\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_mape = float(\"inf\")\n",
    "        best_model_path = f\"best_models/{komoditas}_{provinsi}.pt\"\n",
    "\n",
    "        # Train model\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_train)\n",
    "            loss = criterion(output, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_output = model(X_test)\n",
    "                    val_loss = criterion(test_output, y_test).item()  # Hitung validation loss\n",
    "                    \n",
    "                    test_output_np = test_output.cpu().numpy()\n",
    "                    y_test_np = y_test.cpu().numpy()\n",
    "\n",
    "                    # Inverse transform hasil prediksi dan data aktual\n",
    "                    test_output_np = scaler.inverse_transform(np.concatenate((test_output_np, np.zeros((len(test_output_np), 5))), axis=1))[:, 0]\n",
    "                    y_test_np = scaler.inverse_transform(np.concatenate((y_test_np, np.zeros((len(y_test_np), 5))), axis=1))[:, 0]\n",
    "                    \n",
    "                    # Hitung MAPE\n",
    "                    mape = mean_absolute_percentage_error(y_test_np, test_output_np)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {loss.item():.6f}, Validation Loss: {val_loss:.6f}, MAPE: {mape:.6f}\")\n",
    "\n",
    "                scheduler.step(val_loss)  # Sesuaikan learning rate berdasarkan validation loss\n",
    "\n",
    "                # Simpan model jika validation loss lebih kecil\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_mape = mape  # Simpan MAPE dari model terbaik\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "        # Simpan hasil terbaik untuk komoditas & provinsi ini\n",
    "        mape_results[f\"{komoditas}_{provinsi}\"] = best_mape\n",
    "\n",
    "        # Load model terbaik untuk prediksi masa depan\n",
    "        best_model = MultivariateLSTM(input_size=5).to(device)\n",
    "        best_model.load_state_dict(torch.load(best_model_path))\n",
    "        best_model.eval()\n",
    "        \n",
    "        # Prediksi masa depan\n",
    "        last_sequence = X[-1].unsqueeze(0)  # Data terakhir sebagai input\n",
    "        future_preds = []\n",
    "\n",
    "        for _ in range(predict_periods):\n",
    "            with torch.no_grad():\n",
    "                next_pred = best_model(last_sequence).item()  # Prediksi harga komoditas saja\n",
    "            future_preds.append(next_pred)\n",
    "            \n",
    "            # Ambil nilai USD/IDR terakhir (5 fitur)\n",
    "            last_usd_features = last_sequence[:, -1, 1:].cpu().numpy()\n",
    "\n",
    "            # Gabungkan harga prediksi + USD/IDR\n",
    "            next_pred = np.array([[next_pred]])\n",
    "            next_input = np.concatenate((next_pred, last_usd_features), axis=1)  \n",
    "\n",
    "            # Konversi ke tensor\n",
    "            next_input = torch.tensor(next_input, dtype=torch.float32).unsqueeze(0).to(device)  \n",
    "            last_sequence = torch.cat([last_sequence[:, 1:, :], next_input], dim=1) \n",
    "\n",
    "        # Konversi kembali ke skala asli (hanya untuk harga komoditas)\n",
    "        future_preds = np.array(future_preds).reshape(-1, 1)\n",
    "        future_preds = scaler.inverse_transform(np.concatenate((future_preds, np.zeros((len(future_preds), 5))), axis=1))[:, 0]\n",
    "\n",
    "        # Simpan hasil prediksi\n",
    "        for i, pred in enumerate(future_preds):\n",
    "            date = pd.to_datetime(predict_start) + pd.Timedelta(days=i)\n",
    "            all_predictions.append({\n",
    "                'id': f\"{komoditas}/{provinsi}/{date.strftime('%Y-%m-%d')}\",\n",
    "                'price': pred\n",
    "            })\n",
    "\n",
    "# Simpan hasil prediksi ke CSV\n",
    "submission_df = pd.DataFrame(all_predictions)\n",
    "submission_df.to_csv('submission_multivariate_lstm_mape_validation.csv', index=False)\n",
    "\n",
    "# Hitung dan tampilkan rata-rata MAPE dari semua model terbaik\n",
    "avg_mape = np.mean(list(mape_results.values()))\n",
    "print(f\"\\nRata-rata MAPE dari model terbaik: {avg_mape:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rata-rata MAPE keseluruhan: 0.140867\n",
      "\n",
      "Prediksi selesai dan disimpan. Model terbaik telah disimpan berdasarkan MAPE terendah!\n"
     ]
    }
   ],
   "source": [
    "# Hitung rata-rata MAPE\n",
    "avg_mape = np.mean(list(mape_results.values()))\n",
    "print(f\"\\nRata-rata MAPE keseluruhan: {avg_mape:.6f}\")\n",
    "\n",
    "print(\"\\nPrediksi selesai dan disimpan. Model terbaik telah disimpan berdasarkan MAPE terendah!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
